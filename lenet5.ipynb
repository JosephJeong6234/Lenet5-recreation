{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b2cbb3-a2e1-4167-ae5f-91665859fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd9951b-6197-4c97-bb02-35ee9dd95ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the datasets\n",
    "train = pd.read_csv('./mnist_train.csv')\n",
    "test = pd.read_csv('./mnist_test.csv')\n",
    "\n",
    "# convert pandas dataframe to numpy array\n",
    "train1 = train.to_numpy()\n",
    "test1 = test.to_numpy()\n",
    "\n",
    "# split X and label\n",
    "y_train = train1[:, 0]\n",
    "X_train = train1[:, 1:]\n",
    "\n",
    "y_test = test1[:, 0]\n",
    "X_test = test1[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80ea430c-5409-4500-ae9f-85dd3e8ae15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the datasets work\n",
    "#normalize\n",
    "X_train = X_train/255.\n",
    "X_test = X_test/255.\n",
    "\n",
    "#make shape right\n",
    "X_train = X_train.reshape(-1, 1, 28,28) #technically 1 channel of grayscale then 28 by 28\n",
    "X_test = X_test.reshape(-1,1, 28,28)\n",
    "\n",
    "#make the size right (Lenet5 assumes 32 x 32)\n",
    "X_train = np.pad(X_train, pad_width=((0,0), (0,0), (2,2), (2,2))) #is size [amount of data, channels, height, width) so just add 2 on w and h\n",
    "X_test = np.pad(X_test, pad_width=((0,0), (0,0), (2,2), (2,2))) #total increase is 4 so is now (n, 1, 32,32) as 28+4=32\n",
    "\n",
    "#make torch\n",
    "xTrain = torch.from_numpy(X_train)\n",
    "yTrain = torch.from_numpy(y_train)\n",
    "xTest = torch.from_numpy(X_test)\n",
    "yTest = torch.from_numpy(y_test)\n",
    "\n",
    "#make data type right\n",
    "xTrain = xTrain.to(torch.float32)\n",
    "xTest = xTest.to(torch.float32)\n",
    "\n",
    "#one hot encode the ys\n",
    "yTrainOH = F.one_hot(yTrain, num_classes=10)\n",
    "yTestOH = F.one_hot(yTest, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c3e1a25-56f0-4d71-8976-16b545eab2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
      "(60000, 1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "#checking the data set\n",
    "print(yTest[0:10])\n",
    "print(yTestOH[0:10]) #looks about right\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1172bf44-26b8-4a1b-bbb9-285c78a77bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "class Lenet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Lenet5, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0) #if k=5 and s=1, p=0 for 32 to go to 28\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0) #to go from 14 to 10 need p=0\n",
    "\n",
    "        self.fc1 = nn.Linear(400, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2) #same for both    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        Z1 = self.pool(self.tanh(self.conv1(x)))\n",
    "        Z2 = self.pool(self.tanh(self.conv2(Z1)))\n",
    "        flatten = torch.flatten(Z2, start_dim=1)\n",
    "        x1 = self.tanh(self.fc1(flatten))\n",
    "        x2 = self.tanh(self.fc2(x1))\n",
    "        x3 = self.fc3(x2) #implicit softmax due to CrossEntropyLoss as criterion \n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07037562-0661-4806-b426-b61e1e3b4b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#put on gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Lenet5()\n",
    "model = model.to(device)\n",
    "xTrain = xTrain.to(device)\n",
    "xTest = xTest.to(device)\n",
    "yTrainOH = yTrainOH.to(device)\n",
    "yTestOH = yTestOH.to(device)\n",
    "yTrain = yTrain.to(device)\n",
    "yTest = yTest.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f508911-db67-4c13-862c-7a887591c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(xTrain, yTrain), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(xTest, yTest), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46f8b402-67a3-4e8a-9f63-d278d59dd920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vars/rest of functions \n",
    "def calculate_accuracy(X, Y):\n",
    "    predictions = torch.argmax(X, dim=1)\n",
    "    return (predictions == Y).sum().item()/len(Y)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88f5055f-9401-42e1-9d2a-6e179d62e317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 2.2959, Train Acc: 0.1148, Test Loss: 2.2901, Test Acc: 0.1289\n",
      "Epoch 2/30, Train Loss: 2.2835, Train Acc: 0.1472, Test Loss: 2.2749, Test Acc: 0.1832\n",
      "Epoch 3/30, Train Loss: 2.2640, Train Acc: 0.2557, Test Loss: 2.2485, Test Acc: 0.3552\n",
      "Epoch 4/30, Train Loss: 2.2268, Train Acc: 0.4591, Test Loss: 2.1948, Test Acc: 0.5548\n",
      "Epoch 5/30, Train Loss: 2.1456, Train Acc: 0.5787, Test Loss: 2.0728, Test Acc: 0.6065\n",
      "Epoch 6/30, Train Loss: 1.9623, Train Acc: 0.5932, Test Loss: 1.8131, Test Acc: 0.5854\n",
      "Epoch 7/30, Train Loss: 1.6536, Train Acc: 0.5886, Test Loss: 1.4781, Test Acc: 0.6141\n",
      "Epoch 8/30, Train Loss: 1.3487, Train Acc: 0.6418, Test Loss: 1.2075, Test Acc: 0.6894\n",
      "Epoch 9/30, Train Loss: 1.1147, Train Acc: 0.7094, Test Loss: 1.0062, Test Acc: 0.7470\n",
      "Epoch 10/30, Train Loss: 0.9446, Train Acc: 0.7584, Test Loss: 0.8625, Test Acc: 0.7846\n",
      "Epoch 11/30, Train Loss: 0.8242, Train Acc: 0.7892, Test Loss: 0.7604, Test Acc: 0.8076\n",
      "Epoch 12/30, Train Loss: 0.7373, Train Acc: 0.8086, Test Loss: 0.6853, Test Acc: 0.8212\n",
      "Epoch 13/30, Train Loss: 0.6723, Train Acc: 0.8232, Test Loss: 0.6284, Test Acc: 0.8340\n",
      "Epoch 14/30, Train Loss: 0.6219, Train Acc: 0.8340, Test Loss: 0.5833, Test Acc: 0.8444\n",
      "Epoch 15/30, Train Loss: 0.5814, Train Acc: 0.8435, Test Loss: 0.5468, Test Acc: 0.8534\n",
      "Epoch 16/30, Train Loss: 0.5482, Train Acc: 0.8511, Test Loss: 0.5162, Test Acc: 0.8615\n",
      "Epoch 17/30, Train Loss: 0.5204, Train Acc: 0.8585, Test Loss: 0.4906, Test Acc: 0.8682\n",
      "Epoch 18/30, Train Loss: 0.4967, Train Acc: 0.8643, Test Loss: 0.4687, Test Acc: 0.8737\n",
      "Epoch 19/30, Train Loss: 0.4761, Train Acc: 0.8691, Test Loss: 0.4499, Test Acc: 0.8773\n",
      "Epoch 20/30, Train Loss: 0.4582, Train Acc: 0.8739, Test Loss: 0.4327, Test Acc: 0.8818\n",
      "Epoch 21/30, Train Loss: 0.4424, Train Acc: 0.8780, Test Loss: 0.4179, Test Acc: 0.8850\n",
      "Epoch 22/30, Train Loss: 0.4283, Train Acc: 0.8809, Test Loss: 0.4047, Test Acc: 0.8881\n",
      "Epoch 23/30, Train Loss: 0.4157, Train Acc: 0.8838, Test Loss: 0.3929, Test Acc: 0.8907\n",
      "Epoch 24/30, Train Loss: 0.4043, Train Acc: 0.8863, Test Loss: 0.3820, Test Acc: 0.8923\n",
      "Epoch 25/30, Train Loss: 0.3939, Train Acc: 0.8891, Test Loss: 0.3724, Test Acc: 0.8939\n",
      "Epoch 26/30, Train Loss: 0.3845, Train Acc: 0.8910, Test Loss: 0.3636, Test Acc: 0.8955\n",
      "Epoch 27/30, Train Loss: 0.3759, Train Acc: 0.8938, Test Loss: 0.3551, Test Acc: 0.8984\n",
      "Epoch 28/30, Train Loss: 0.3679, Train Acc: 0.8954, Test Loss: 0.3474, Test Acc: 0.9007\n",
      "Epoch 29/30, Train Loss: 0.3604, Train Acc: 0.8971, Test Loss: 0.3405, Test Acc: 0.9019\n",
      "Epoch 30/30, Train Loss: 0.3534, Train Acc: 0.8987, Test Loss: 0.3338, Test Acc: 0.9033\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * batch_x.size(0)\n",
    "        correct += (outputs.argmax(1) == batch_y).sum().item()\n",
    "        total += batch_x.size(0)\n",
    "    \n",
    "    avg_train_loss = train_loss / total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    model.eval()\n",
    "    test_loss, test_correct, test_total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "\n",
    "            test_loss += loss.item() * batch_x.size(0)\n",
    "            test_correct += (outputs.argmax(dim=1) == batch_y).sum().item()\n",
    "            test_total += batch_x.size(0)\n",
    "\n",
    "    avg_test_loss = test_loss / test_total\n",
    "    test_acc = test_correct / test_total\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Loss: {avg_test_loss:.4f}, Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f611e-aba5-4c75-b541-b4eb0049f753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch1]",
   "language": "python",
   "name": "conda-env-torch1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
